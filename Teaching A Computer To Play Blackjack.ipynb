{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teaching A Computer To Play Blackjack\n",
    "\n",
    "*by Kelsey Cribari, Brandt Reutimann, and Courtney Schulze - December, 2017*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "*The What. The Why. The How.*\n",
    "\n",
    "It all started when a member of the iconic trio went to Las Vegas for a weekend over the semester. While she had never gambled before, everyone would soon find out that Courtney loved blackjack ... a lot. Although her wallet was empty, Courtney left Vegas rich in experience and Blackjack knowledge. Born out of that trip and lost money came an idea, an idea for a CS440 final project.\n",
    "\n",
    "For those of you reading this report who might not know, in the game of blackjack, players are dealt two cards, and they are dealt cards until they reach or get as close as then can to a card value totaling twenty-one. If the player’s total goes over twenty-one, the player busts and they lose their money. If the player’s total is less than the dealer’s total, the player also loses their money. Really, the player tends to lose their money quite a lot. However, there is a generally universally accepted basic blackjack strategy. If players play with this proper strategy, then the dealer only has about a 0.05% advantage. In other words, “if you are playing for $100 per hand, you can expect to lose about 50 cents each hand.” A chart of this proper strategy is found below:\n",
    "\n",
    "![alt text](https://www.blackjackclassroom.com/wp-content/uploads/2017/02/Blackjack-Basic-Strategy-Chart.png \"Basic Blackjack Strategy\")\n",
    "(Photo courtesy of [Blackjack Classroom](https://www.blackjackclassroom.com/blackjack-basic-strategy-charts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this interesting nature of the basic blackjack strategy, we thought it would be a fascinating project to try training a computer to play blackjack through basic artifical intelligence principles, namely reinforcement learning. Would the computer naturally learn the strategy that all professional blackjack players accept as “proper”? That’s what we set to find out.\n",
    "\n",
    "### Overview of Methods:\n",
    "* Temporal Difference Reinforcement Learning: In the inital implementation of the game, we used reinforcements of 1 if you beat the dealer, 0 if you push (tie with the dealer), and -1 if you lose.\n",
    "\n",
    "### Overview of Results:\n",
    "** put results here **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "*The steps we took. The resources we used. The work we shared.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase One:\n",
    "The first phase was comprised of creating deck, player, and dealer representations for the game. Feel free to run the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deck:\n",
    "*Main Author: Brandt Reutimann*\n",
    "\n",
    "The deck is a relatively standard card deck, except suits are naturally ignored. All face cards are represented by 10's (since for blackjack, a king is the same as a queen which is the same as a ten). \n",
    "\n",
    "A new deck is shuffled by default. This feature can be turned off by passing ```deck = BlackJackDeck (shuffleCards = False)```.\n",
    "\n",
    "Suits and faces can be activated with ```deck = BlackJackDeck (SuitsAndFaces = True)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.Deck import BlackJackDeck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of drawing 10 random cards without suits or faces:\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "5\n",
      "10\n",
      "A\n",
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print (\"Example of drawing 10 random cards without suits or faces:\")\n",
    "deck = BlackJackDeck()\n",
    "for i in range (0, 10):\n",
    "    print (deck.drawCard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of drawing 10 random cards with suits and faces:\n",
      "(3, 'H')\n",
      "('J', 'S')\n",
      "('K', 'H')\n",
      "(8, 'D')\n",
      "(6, 'H')\n",
      "('Q', 'H')\n",
      "('J', 'D')\n",
      "(2, 'H')\n",
      "(7, 'H')\n",
      "(7, 'D')\n"
     ]
    }
   ],
   "source": [
    "print (\"Example of drawing 10 random cards with suits and faces:\")\n",
    "deckSuits = BlackJackDeck(SuitsAndFaces = True)\n",
    "for i in range (0, 10):\n",
    "    print (deckSuits.drawCard())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player:\n",
    "*Main Author: Courtney Schulze*\n",
    "\n",
    "A player consists of a hand and a current card count (which is the current card total of the cards in their hand). A player has a list of valid moves they can make (either stand or hit). When a player hits, a card is drawn from the deck and added to the player's hand. If the card count after the new card is greater than 21, then the player busts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Player import Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The player's current hand is: [10, 8]\n",
      "The cards in the player's hand total: 18\n",
      "Valid moves: ['stand', 'hit', 'double']\n"
     ]
    }
   ],
   "source": [
    "# create both deck and player\n",
    "deck = BlackJackDeck()\n",
    "player = Player()\n",
    "\n",
    "#put first two cards in player's hand\n",
    "player.addCardToHand(deck.drawCard())\n",
    "player.addCardToHand(deck.drawCard())\n",
    "\n",
    "print(\"The player's current hand is: \" + str(player.getHand()))\n",
    "print(\"The cards in the player's hand total: \" + str(player.getCardCount()))\n",
    "print(\"Valid moves: \" + str(player.validMoves()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The player takes a card. Here are the results: [10, 8, 7]\n",
      "The player busted based on the previous hit: True\n"
     ]
    }
   ],
   "source": [
    "print(\"The player takes a card. Here are the results: \" + str(player.hit(deck)))\n",
    "print(\"The player busted based on the previous hit: \" + str(player.bust))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if the player keeps hitting until they get to a total greater than 21?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (player.getCardCount() < 21):\n",
    "    while not player.bust:\n",
    "        result = player.hit(deck)\n",
    "        print(\"Player's hand: \" + str(player.getHand()))\n",
    "    print(\"Player busted! Card total was: \" + str(player.getCardCount()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealer:\n",
    "*Main Author: Kelsey Cribari*\n",
    "\n",
    "A dealer is pretty much a player, but they have a more specific ruleset they have to follow in terms of valid moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.Dealer import BlackJackDealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dealer's faceup card: 5\n",
      "Dealer's hand: [3, 5]\n",
      "The dealer has to: hit\n"
     ]
    }
   ],
   "source": [
    "# create both dealer and deck\n",
    "deck = BlackJackDeck()\n",
    "dealer = BlackJackDealer()\n",
    "\n",
    "dealer.hand.append(deck.drawCard())\n",
    "# deal second card to dealer\n",
    "dealerFaceCard = deck.drawCard()\n",
    "dealer.hand.append(dealerFaceCard)\n",
    "# keep track of the card that is face up on the dealer so the player knows what to base their moves off of\n",
    "dealer.faceUpCard = dealerFaceCard\n",
    "\n",
    "print(\"Dealer's faceup card: \" + str(dealer.faceUpCard))\n",
    "print(\"Dealer's hand: \" + str(dealer.hand))\n",
    "print(\"The dealer has to: \" + str(dealer.dealerValidMoves()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase Two:\n",
    "This phase consisted of doing the game representation and writing the trainQ and testQ methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game\n",
    "*Main Authors: Kelsey Cribari and Brandt Reutimann*\n",
    "\n",
    "** Kelsey is going to write things here **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Game import BlackJackGame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforcement Learning\n",
    "\n",
    "*Main Authors: Kelsey Cribari and Brandt Reutimann*\n",
    "\n",
    "We used a temporal difference strategy for training the player agent in our BlackJack game. Essentially the player is reinforced +1 for a win, -1 for a loss, and 0 for a push (draw). If the player doubles down and wins, it is reinforced +2, but conversely if it loses it is reinforced -2. All the reinforcement is contained in our trainQ function.\n",
    "\n",
    "We then use a testQ function to simulate playing a number of games. The testQ function keeps track of wins and earnings to simulate how well the agent performs using it's knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling testQ\n",
      "Initial Hand: [10, 5], Bet: 5, Player: [10, 5], Dealer: [2, 3, 10], Result: push\n",
      "Win rate was: 45.9, Earnings: $110\n"
     ]
    }
   ],
   "source": [
    "game = BlackJackGame()\n",
    "Q = game.trainQ(100000, .6, .8)\n",
    "print ('calling testQ')\n",
    "winRate, earnings = game.testQ(Q, 1000, verbose=True)\n",
    "print ('Win rate was: {}, Earnings: ${}'.format(winRate, earnings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Learning Rate & Epsilon Decay\n",
    "*Main Authors: Courtney Schulze*\n",
    "\n",
    "In order to make our learning algorithm effective, we wanted to find the right combination of learning rate and epsilon decay that would maximize winning. \n",
    "\n",
    "If learning rate is too high the agent might become too confident if it got lucky on a move that is actually bad.\n",
    "For example, let's say the agent hits on a 20 against a dealer 10 and luckily receives an Ace, thus winning the hand. If the learning rate is too high, the agent may have to much confidence in hitting in this scenario again. Or the opposite scenario is that AI becomes risk adverse as result of hitting and losing in a strategically correct scenario.\n",
    "\n",
    "For epsilon, we want to insure that the agent explores as many random moves as possible. BlackJack has a lot of possible scenarios for the agent to encounter. There are combinations of sums and Aces all the way up to 21, in addition to variance in the dealer's upcard. In order to learn to be a BlackJack expert, the agent has to encounter all of these scenarios and explore different moves to determine which strategy is best. If epsilon is too low, the AI might not enough experimentation before relying on it's own experience (Q table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average win rate for learningRate = 0.6 and epsilonDecayFactor = 0.8: 45.10000000000001\n"
     ]
    }
   ],
   "source": [
    "def averageWinRate(learningRate, epsilonDecayFactor):\n",
    "    sumWin = 0.0\n",
    "    for i in range(10):\n",
    "        game = BlackJackGame()\n",
    "        Q = game.trainQ(100000, learningRate, epsilonDecayFactor)\n",
    "        winRate, _ = game.testQ(Q, 1000)\n",
    "        sumWin += winRate\n",
    "    \n",
    "    return sumWin / 10\n",
    "\n",
    "print(\"Average win rate for learningRate = 0.6 and epsilonDecayFactor = 0.8: \" + str(averageWinRate(0.6, 0.8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most version of the average win rate above, the win rate comes out to about 45%. This makes sense: when playing with proper strategy, the house should only have about a 0.05% advantage, bringing the player's win rate to 45%. According to [Wizard of Odds](https://wizardofodds.com/games/blackjack/appendix/4/), the probability of a net win in blackjack is 42.42%. If ties are ignored, that jumps to about 46.35%. However, we wondered if we could make that win rate better by playing around with the learning rate and epsilon decay factor for 100,000 iterations. Therefore, Courtney put on her investigation hat to see how high we could get that win rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please be prepared to wait a while.\n",
      "Testing learningRate = 0.5 and epsilonDecayFactor = 0.5\n",
      "Average win rate for learningRate = 0.5 and epsilonDecayFactor = 0.5: 45.5\n",
      "Testing learningRate = 0.99 and epsilonDecayFactor = 0.3\n",
      "Average win rate for learningRate = 0.99 and epsilonDecayFactor = 0.3: 45.13999999999999\n",
      "Testing learningRate = 0.99 and epsilonDecayFactor = 0.8\n",
      "Average win rate for learningRate = 0.99 and epsilonDecayFactor = 0.8: 44.49\n",
      "Testing learningRate = 0.3 and epsilonDecayFactor = 0.3\n",
      "Average win rate for learningRate = 0.3 and epsilonDecayFactor = 0.3: 46.58000000000001\n",
      "Testing learningRate = 0.3 and epsilonDecayFactor = 0.99\n",
      "Average win rate for learningRate = 0.3 and epsilonDecayFactor = 0.99: 44.53\n"
     ]
    }
   ],
   "source": [
    "def testDifferentValues():\n",
    "    print(\"Testing learningRate = 0.5 and epsilonDecayFactor = 0.5\")\n",
    "    print(\"Average win rate for learningRate = 0.5 and epsilonDecayFactor = 0.5: \" + str(averageWinRate(0.5, 0.5)))\n",
    "    \n",
    "    print(\"Testing learningRate = 0.99 and epsilonDecayFactor = 0.3\")\n",
    "    print(\"Average win rate for learningRate = 0.99 and epsilonDecayFactor = 0.3: \" + str(averageWinRate(0.99, 0.3)))\n",
    "    \n",
    "    print(\"Testing learningRate = 0.99 and epsilonDecayFactor = 0.8\")\n",
    "    print(\"Average win rate for learningRate = 0.99 and epsilonDecayFactor = 0.8: \" + str(averageWinRate(0.99, 0.8)))\n",
    "    \n",
    "    print(\"Testing learningRate = 0.3 and epsilonDecayFactor = 0.3\")\n",
    "    print(\"Average win rate for learningRate = 0.3 and epsilonDecayFactor = 0.3: \" + str(averageWinRate(0.3, 0.3)))\n",
    "    \n",
    "    print(\"Testing learningRate = 0.3 and epsilonDecayFactor = 0.99\")\n",
    "    print(\"Average win rate for learningRate = 0.3 and epsilonDecayFactor = 0.99: \" + str(averageWinRate(0.3, 0.99)))\n",
    "\n",
    "print(\"Please be prepared to wait a while.\")\n",
    "testDifferentValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at these results, the best thing to do seems to be use a bit lower of a learning rate, and don't make the epsilonDecayFactor too large or small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betting Strategy\n",
    "\n",
    "In order to make the game more interesting we wanted to incorporate some betting strategy. We figured that implementing a learning strategy for betting would be trivial. This is because in the long run the goal is to maximize earnings. Therefore, the agent should eventually determine that it is losing money the longer it plays and hence always gamble the minimum. This is an assumption that will need to be tested in future experiments.\n",
    "\n",
    "For our project we decided to use a different approach to bettting. We call this strategy hotstreak betting. Essentially, the more wins the agent gets consecutively the higher it will bet with each consecutive win. We wanted to model it after the fallacy of many gamblers: \"I'm on a lucky streak right now, I should bet more\". We thought this was an interesting notion to test in our agent, especially for observing how this betting strategy effects earnings.\n",
    "\n",
    "We implemented this strategy by keeping a count of consecutive wins. If the agent loses this count is reset to 0 and if the agent draws we decrement the count by 1 (maybe shaking it's feeling of luck a little). Then in a determineBet function we use a soft exponential curve to determine how much the agent will bet. The hardness (exponetial slope) of this curve can be modified by increasing the streak factor. You can also disable this hotstreak betting strategy by setting the hotstreak flag to false. How much the player bets is based on a minimum bet amount, if there is no hotstreak strategy then the agent always bets the minimum unless doubling down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement hotstreak betting\n",
    "def determineBet (self, consecutiveWins, minBet = 5, streakFactor = 1.2, hotstreak = True):\n",
    "    if hotstreak is False:\n",
    "        return minBet\n",
    "    return round(minBet ** streakFactor) if consecutiveWins > 0 else minBet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "*The results we got.*\n",
    "\n",
    "#### Comparing our agent to a random player\n",
    "\n",
    "As we have observed earlier, our agent's win rate will hover around 45 - 46%. Let's see how this compares to a random player.\n",
    "\n",
    "We are going to modify averageWinRate to take a few extra arguments. Mostly, we want to specify iterations to see if our agent improves with more training. Also, we want to add an argument to calculate average win rate for a random player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify average win rate to include iteration parameter\n",
    "def averageWinRate(learningRate, epsilonDecayFactor, iterations = 100000, random = False):\n",
    "    sumWin = 0.0\n",
    "    for i in range(10):\n",
    "        game = BlackJackGame()\n",
    "        Q = {}\n",
    "        if random:\n",
    "            winRate, _ = game.testQ(Q, 5000, esp = 1)\n",
    "        else:\n",
    "            Q = game.trainQ(iterations, learningRate, epsilonDecayFactor)\n",
    "            winRate, _ = game.testQ(Q, 5000) # Also up the number of games played to 5000\n",
    "        sumWin += winRate\n",
    "    \n",
    "    return sumWin / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete for 10 iterations. Time 2.37 seconds\n",
      "Training complete for 100 iterations. Time 2.51 seconds\n",
      "Training complete for 1000 iterations. Time 3.26 seconds\n",
      "Training complete for 10000 iterations. Time 9.22 seconds\n",
      "Training complete for 100000 iterations. Time 70.34 seconds\n"
     ]
    }
   ],
   "source": [
    "winRates = []\n",
    "iters = []\n",
    "for i in range (1, 6):\n",
    "    # Test iterations in powers of 10\n",
    "    iterations = 10 ** i\n",
    "    iters.append(iterations)\n",
    "    st = time.time()\n",
    "    avgWin = averageWinRate(.3, .99, iterations = iterations)\n",
    "    et = time.time()\n",
    "    winRates.append(avgWin)\n",
    "    print ('Training complete for {} iterations. Time {:.2f} seconds'.format(iterations, et - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31.922000000000004,\n",
       " 31.5,\n",
       " 31.597999999999995,\n",
       " 31.629999999999995,\n",
       " 31.427999999999997]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randRates = []\n",
    "rIters = []\n",
    "for i in range (1,6):\n",
    "    iterations = 10 ** i\n",
    "    rIters.append(iterations)\n",
    "    avgWin = averageWinRate(.3, .99, random = True)\n",
    "    randRates.append(avgWin)\n",
    "randRates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHxBJREFUeJzt3XuYXVWZ5/HvryqpXKpCroVEQgg0t0YmBCgRoW0QFTMQ\nwbF9FEcabNuOoqN4wQxRZ3zQZ+bBa6OtdhvRGQRaRETB9CAiEu8kJpDEIEFELkLAVBIDVAWqUlXv\n/LH3SU4q51aV2nWqzv59nuc8dc7aZ5/9Li773WutvfZSRGBmZvnVVO8AzMysvpwIzMxyzonAzCzn\nnAjMzHLOicDMLOecCMzMcs6JwMws55wIzMxyzonAzCznJtQ7gFrMmTMnFixYUO8wzMzGlXXr1m2L\niPZq3xsXiWDBggWsXbu23mGYmY0rkh6r5XvuGjIzyzknAjOznMs8EUhqlnSfpJVFZe+VtFnS/ZI+\nnXUMZmZW3miMEVwGPAAcBCDplcAFwIkR0SPp4FGIwczMysi0RSBpHnAecE1R8aXAVRHRAxARW7OM\nwczMKsu6a+hqYBkwUFR2DPAKSasl/VTSSzOOwczMKsgsEUhaAmyNiHWDNk0AZgGnAR8GbpKkEvsv\nlbRW0trOzs6swjQzy70sxwjOAM6XdC4wGThI0vXAE8AtkayRuUbSADAH2OdsHxErgBUAHR0dXk/T\nzBrWwEDwzPO72d7dQ+dzvWzv7mF7Vy/bunp44ynzOHx2a6bHzywRRMRyYDmApLOAyyPiIknvAl4J\n3C3pGKAF2JZVHGZm9dDT18/2rt49J/RtXT1s7+5l23Pp364etnX1sr2rhx3dvfQN7H+92yQ4+fCZ\n4zcRVPAN4BuSNgG9wCVp68DMbMyKCJ59oS85oacn9+3pybxQtr177+fnXugr+TuTJzYxp20Ss9sm\nceiMySw8dDqz21rSsuRv4f3MqS00N+3Xcz7iRiURRMQqYFX6vhe4aDSOa2ZWye7+AXZ099KZXqVv\nL1y5d/XSWXxyT7trdveXvmadOXXinpP38S8+iPa2ScxubWHOtOTv7LZJSVlbC1NbmikxLFpX4+JZ\nQ2ZmtYgIunr6irpj9j2R7z3BJ9ueeX53yd9paW5iTltyIm9vm8RxhxyUXqm37L16b53EnGktzJra\nwoTm8f2QBicCMxvT+voH2LGrt6g7Zt/+9UJ/e6G8p2+g5O9MnzJxz0n82EOmcXrrpKLumJY93TVz\n2lpomzRhzF21Z8mJwMxG3a7ePrY918u27vL97YXB1b/s6qXUKOLEZjG7dW+/+lEHt+29am/dt799\nVmsLLRPG91V7lpwIzOyA9Q8EO3f17rlK37bn7pi93TLFJ/nnd/eX/J1pkybs6Vc/sr2VU4+Ylfav\nJ/3shX73Oa2TOGhKvq7as+REYGYlvbC7f98umMEDqEVX7ju6eylx9yPNTWJWa8ueK/UFs6fu0wVT\nfKfMrNYWJk9sHv2KmhOBWV5UmrS050q+6F737t7SV+2tLc17TuSHzZrKSfNnpIOnLWn53pP89CkT\naRqF2x/twDgRmI1j+0xa6u7ZO1lpiJOWZrW27LkL5sSZM4r61wvlabdM2ySmtPiqvdE4EZiNIYMn\nLRWu0g9k0tKLp4+NSUs2djkRmGWs0qSlPSf4A5i0NHvP/e1je9KSjV1OBGZD5ElL1micCMzYd9JS\n8UPChj1pqbXypKXZbS1My9mkJRu7nAisYY30pKXZRZOWCgOnnrRkjcCJwMaNSpOWirtphjtpac8V\nuyctWc44EVhd1T5pqZcd3T1DnrQ0u61lzwCqJy2ZleZEYCNqKJOWtnf10tVT+vbHwqSl2VUmLc1u\nm8QMT1oyOyBOBFbVSE9amt3WwonzPGnJbKxwIsihSpOWSj0kbKiTlor72z1pyWzscyJoEKM5aalw\nkvekJbPG4EQwRg1l0tL27l527qo8aakw67TspKW2Fma1etKSWR5lnggkNQNrgScjYklR+YeAzwLt\nEbEt6zjGgqwmLe27CIcnLZnZ0IxGi+Ay4AHgoEKBpMOAc4DHR+H4o+753n6+suoPPLKt25OWzGzM\nyzQRSJoHnAf8L+CDRZv+GVgG3Jrl8eshIvjv393IDzZu4fBZyf3s5SYtFbprPGnJzOop6xbB1SQn\n/GmFAkkXkHQTbWjEk99Xf/ZHbtuwhWWLj+XdZx1V73DMzKrKrI9B0hJga0SsKyqbCnwE+J817L9U\n0lpJazs7O7MKc0TdvXkrn/rhZpYsnMulZ/5VvcMxM6tJlp3NZwDnS3oUuBE4G7gOOALYkJbPA+6V\ndMjgnSNiRUR0RERHe3t7hmGOjIc7u3jfjfdx/NyD+MwbT3RXj5mNG5l1DUXEcmA5gKSzgMsj4u+K\nv5Mmg47xftfQsy/s5p++uZaW5iZWXNzhWbFmNq54HsEB6h8I3n/jeh7fvosb3vEyDp0xpd4hmZkN\nyagkgohYBawqUb5gNI6fpc/96EF+snkrn3z9CbzsyNn1DsfMbMh8Q/oB+MGGLXxl1cO85dT5XPSy\n+fUOx8xsWJwIhmnTk8/w4Zs30HH4TK48/yUeHDazccuJYBi2dfXwzuvWMXNqC/960Sme6Wtm45oH\ni4eot2+Ad19/L9u6erj5XafTPm1SvUMyMzsgTgRD9ImV97Pm0R184cJF/Kd50+sdjpnZAXOfxhDc\nsPoxrr/ncd555pFcsOjQeodjZjYinAhqtOaRHXz81vs585h2lr32uHqHY2Y2YpwIavDkzue59Pp1\nHDZrKl98y0lectHMGooTQRXP9/bzzuvW0ts3wNcu7mD6lIn1DsnMbER5sLiCwtoC9295lmsu7uCo\ng9vqHZKZ2Yhzi6CCFenaApefcyyv+usX1TscM7NMOBGUserBrVyVri3w7rO8toCZNS4nghL+2NnF\ne791H399yEF8+o0L/fgIM2toTgSDFNYWmNjcxIqLT2Fqi4dRzKyxOREUKawt8Nj2XXzlrSczb+bU\neodkZpY5J4Iin78zWVvg4687ntO8toCZ5YQTQeoHG7bw5bsf5i2nHsZFpx1e73DMzEaNEwFw/5bi\ntQVO8OCwmeVK5olAUrOk+yStTD9/RtJmSRslfU/SjKxjqGR7Vw9Lv+m1Bcwsv0bjrHcZ8EDR5zuB\nEyJiIfB7YPkoxFDS7v4BLr0hWVvgq39/itcWMLNcyjQRSJoHnAdcUyiLiB9FRF/68R5gXpYxVPKJ\nH/yONY/s4FN/t5CF8+raMDEzq5usWwRXA8uAgTLb3w7cnnEMJf376se57p7HeOffHsnrT/LaAmaW\nX5klAklLgK0Rsa7M9o8CfcANZbYvlbRW0trOzs4Rje03j+7g47dtStYWWOy1Bcws37JsEZwBnC/p\nUeBG4GxJ1wNIehuwBHhrRESpnSNiRUR0RERHe3v7iAW1JV1bYN7MqXzxQq8tYGaWWSKIiOURMS8i\nFgAXAj+JiIskLSbpLjo/InZldfxSnu/tZ+l1a3lh9wBfu/gUpk/12gJmZvW4V/JLwDTgTknrJf3b\naBw0IrjilmRtgavfvIijDp42Goc1MxvzRuWJahGxCliVvj9qNI452HfWPsGt67fw4dcey6uP99oC\nZmYFuZk9dd+f/sLs1havLWBmNkhuEkF3Tz8HTZnox0eYmQ2So0TQx9SW5nqHYWY25uQnEfT20epF\nZszM9pObRLCrt5/WSW4RmJkNlptE0NXTx9RJbhGYmQ2Wm0Swq6efNncNmZntJzeJoLunj6nuGjIz\n208uEkFE0N3bR5u7hszM9pOLRPDC7gEGAqa6a8jMbD+5SATdvck6OG3uGjIz208+EkFPkgjcIjAz\n21/VM6OklwMXAa8A5gLPA5uA/wCuj4hnMo1wBHT39APQ6jECM7P9VGwRSLodeAdwB7CYJBEcD3wM\nmAzcKun8rIM8UIWuIU8oMzPbX7VL5L+PiG2DyrqAe9PX5yTNySSyEVToGnKLwMxsfxVbBCWSAJJe\nJel1kiaW+85Ys6dryGMEZmb7GdJgsaTPkaxFfCJwayYRZaDQNeSnj5qZ7a/iJXJ64v9kROxMi+YD\nb0rf/zbLwEZSoWvIE8rMzPZXrUVwC3CjpPdJaga+CdwN/Br4WtbBjZRdvUnXkB8xYWa2v2pjBL+M\niMXADpI7hxQRZ0XEaRHxhVoOIKlZ0n2SVqafZ0m6U9JD6d+ZB1yLKrp7+pjYLCZNcCIwMxus2u2j\nEySdB2wFXg+cKOk2SScO4RiXAQ8Ufb4CuCsijgbuSj9nKlmdzN1CZmalVOsa+j6wCDgT+HJEfBJ4\nF/BeSVW7hiTNA84DrikqvgC4Nn1/LUmCyVR3b7/HB8zMyqh2djw8IpZIagHuAYiILcA7JC2q4fev\nBpYB04rKXhQRT6XvnwZeVGpHSUuBpQDz58+v4VDleb1iM7PyqrUIVkj6NfBT4PPFGyJifaUdJS0B\ntkbEunLfiYgAosy2FRHREREd7e3tVcKsrLu335PJzMzKqHh2jIh/Af5lmL99BnC+pHNJHkdxkKTr\ngT9LmhsRT0maSzL+kKnunj4/XsLMrIxqg8Ufq3RXj6Sz0yv//UTE8oiYFxELgAuBn0TERcBtwCXp\n1y5hFCamdff0eVaxmVkZ1c6OvwVWSnqB5NlCnSRX90eTDCL/GPjfQzzmVcBNkv4ReIy9E9Qy093b\n564hM7MyqnUN3UryhNGjSbp65gLPAtcDSyPi+VoOEhGrgFXp++3Aq4Yf8tDt6un3YLGZWRk1XSZH\nxEPAQxnHkpmuHq9XbGZWTsOvUNbXP0BP34AnlJmZldHwiaC7t7A6mbuGzMxKafhEsKvXi9KYmVVS\nUyKQdIykuyRtSj8vlPSxbEMbGV6dzMysslpbBF8DlgO7ASJiI8ncgDFv7+pk7hoyMyul1kQwNSLW\nDCrrG+lgstDtriEzs4pqTQTbJP0V6XOBJL0ReKryLmOD1ys2M6us1rPje4AVwHGSngQeAd6aWVQj\naO9gsbuGzMxKqTURRES8WlIr0BQRz0k6IsvARkqXB4vNzCqqtWvouwAR0R0Rz6VlN2cT0sjalXYN\n+RETZmalVbxMlnQc8BJguqQ3FG06iOThc2NeoUXgmcVmZqVVOzseCywBZgCvKyp/DvinrIIaSbt6\n+5gysZnmJtU7FDOzManWp4++PCJ+PUoxjaiuHq9OZmZWSa1nyPskvYekm2hPl1BEvD2TqEbQrl6v\nTmZmVkmtg8XXAYcAryVZv3geSffQmOfVyczMKqs1ERwVEf8D6I6Ia4HzgJdlF9bI6e7pd4vAzKyC\nWhPB7vTvTkknANOBg7MJaWR5mUozs8pqTQQr0kXsP0ay+PzvgE9V2kHSZElrJG2QdL+kK9PyRZLu\nkbRe0lpJpx5QDapw15CZWWVVz5CSmoBnI+IvwM+AI2v87R7g7IjokjQR+IWk24FPAFdGxO2SzgU+\nDZw1rOhr4K4hM7PKqrYIImIAWDbUH45EV/pxYvqK9HVQWj4d2DLU3x6K7t4+TyYzM6ug1jPkjyVd\nDnwb6C4URsSOSjtJagbWAUcBX46I1ZLeD9wh6bMkiej0YUVeg4hgV69bBGZmldSaCN6c/n1PUVlQ\npZsoIvqBRZJmAN9LB5qXAh+IiO9KehPwdeDVg/eVtDT9LvPnz68xzH319A3QPxAeLDYzq6CmM2RE\nHNCTRiNip6S7gcXAJcBl6abvANeU2WcFyaOv6ejoiOEcd88yle4aMjMrK7PF6yW1py0BJE0BXgNs\nJhkTODP92tnAQ1nFsGdRGrcIzMzKyvIMORe4Nh0naAJuioiVknYCX5A0AXiBtPsnC3uWqfQjqM3M\nysosEaQL3J9UovwXwClZHbdYtxelMTOrquYzpKRDgcOL94mIn2UR1Ejp7i10DblFYGZWTk2JQNKn\nSO4c+h3QnxYHyQSzMev5NBFMnuhEYGZWTq0tgtcDx0ZET5bBjLT+geRmo4nNmY2Jm5mNe7WeIf9I\nMjN4XOkbGADw6mRmZhXU2iLYBayXdBfJM4QAiIj3ZRLVCOnrT1oEE5wIzMzKqjUR3Ja+xpVC15Bb\nBGZm5dU6s/jarAPJQp/HCMzMqqqYCCTdFBFvkvRbkruE9hERCzOLbAT0e4zAzKyqai2CwjOBlmQd\nSBYKLQKPEZiZlVctEbxZ0q+AeyOibzQCGkmFwWK3CMzMyquWCOYBVwPHpd1DvwR+Bfyq2loEY8He\nFoHHCMzMyqmYCCLicgBJLUAHySIy/0CyhvHOiDg++xCHrzBGMKHZLQIzs3JqvX10CsnyktPZu7zk\nb7MKaqQUWgTNciIwMyun2l1DK4CXAM8Bq0m6hT6fLmQ/5vUPBE2CJo8RmJmVVa3zfD4wCXgaeBJ4\nAtiZdVAjZXd/eHzAzKyKamMEiyWJpFVwOvAh4ARJO4BfR8THRyHGYesfGPAdQ2ZmVVQdI4iIADal\nK4s9k76WAKcCYzoR9A2EB4rNzKqoNkbwPpKWwOnAbtJbR4FvMA4Gi/sHwpPJzMyqqNYiWAB8B/hA\nRDyVfTgj62VHzKbNy1SamVVUbYzgg8P9YUmTSVYwm5Qe5+bCmIKk9wLvIVnt7D8iYtlwj1PJeQvn\nct7CuVn8tJlZw8jycrkHODsiuiRNBH4h6XaSOQkXACdGRI+kgzOMwczMqsgsEaSDzF3px4npK4BL\ngasKy15GxNasYjAzs+oyvcleUrOk9cBW4M6IWA0cA7xC0mpJP5X00jL7LpW0VtLazs7OLMM0M8u1\nTBNBRPRHxCKSh9edKukEklbILOA04MPATelchcH7roiIjojoaG9vzzJMM7NcG5VptxGxE7gbWEwy\nO/mWSKwBBoA5oxGHmZntL7NEIKld0oz0/RTgNcBm4PvAK9PyY4AWYFtWcZiZWWVZ3jU0F7hWUjNJ\nwrkpIlamj7T+hqRNQC9wSTqwbGZmdZDlXUMbgZNKlPcCF2V1XDMzGxo/mtPMLOecCMzMcs6JwMws\n55wIzMxyzonAzCznnAjMzHLOicDMLOecCMzMcs6JwMws55wIzMxyzonAzCznnAjMzHLOicDMLOec\nCMzMcs6JwMws55wIzMxyzonAzCznnAjMzHIuy8XrJ0taI2mDpPslXTlo+4ckhaQ5WcVgZmbVZbl4\nfQ9wdkR0SZoI/ELS7RFxj6TDgHOAxzM8vpmZ1SCzFkEkutKPE9NXpJ//GVhW9NnMzOok0zECSc2S\n1gNbgTsjYrWkC4AnI2JDlsc2M7PaZNk1RET0A4skzQC+J2kh8BGSbqGKJC0FlgLMnz8/yzDNzHJt\nVO4aioidwN3ABcARwAZJjwLzgHslHVJinxUR0RERHe3t7aMRpplZLmV511B72hJA0hTgNcB9EXFw\nRCyIiAXAE8DJEfF0VnGYmVllWXYNzQWuldRMknBuioiVGR7PzMyGIbNEEBEbgZOqfGdBVsc3M7Pa\neGaxmVnOORGYmeWcE4GZWc45EZiZ5ZwTgZlZzjkRmJnlnBOBmVnOORGYmeWcE4GZWc45EZiZ5ZwT\ngZlZzjkRmJnlnBOBmVnOORGYmeWcE4GZWc45EZiZ5ZwTgZlZzjkRmJnlXJaL10+WtEbSBkn3S7oy\nLf+MpM2SNkr6XmGBezMzq48sWwQ9wNkRcSKwCFgs6TTgTuCEiFgI/B5YnmEMZmZWRWaJIBJd6ceJ\n6Ssi4kcR0ZeW3wPMyyoGMzOrLtMxAknNktYDW4E7I2L1oK+8Hbg9yxjMzKyyTBNBRPRHxCKSq/5T\nJZ1Q2Cbpo0AfcEOpfSUtlbRW0trOzs7hBbDxJvihe57MzCoZlbuGImIncDewGEDS24AlwFsjIsrs\nsyIiOiKio729fXgHfmItrC+ZZ8zMLJXlXUPthTuCJE0BXgNslrQYWAacHxG7sjo+AC2t0NsNpXON\nmZkBEzL87bnAtZKaSRLOTRGxUtIfgEnAnZIA7omId2USwaQ2GOiD/l6YMCmTQ5iZjXeZJYKI2Aic\nVKL8qKyOuZ+WtuRvbzcg2PEw9O9OksNAf/q33KvU9qKy/t0lvjPos5qSV1Nz+r4Zmpr2vq9pWzNI\ng75X9L6mbbUeq0S8Q4kjSexmNs5k2SKov5bW5O+vvwTrvwXPbcnmOE0ToWlC+mre+zcCoh9iAAYG\nit6nfwufG4WahpiQyiUdlfiNCvsV71Nzcm3ad9t+xxpqXYab5Gs51jDiMBuCfCSCn38ODj8DXv3x\npJWw30l7AjRP3Pfz4O37lRVO/iPwP125JDHQPyiZ9A96X27bwKDfGKgtIQ0rjoFBv3GgcUSJeg4U\nvd9d4lhR4vcH71dDXRouKY9Eq7Nc4h28rZZEXi3xjkZyrUMc40BjJ4IjzoRTl8LxF8CCv6l3NOU1\nNeHHPo0BEbUl3lqTzrCTa43bRiTJ15jISybe3SXiqJDIh1KXRkzKw211vu4LcPjLMw2xsRPB1Flw\n7mfqHYWNF3vGOZyU6y6iQnKt1NqrIemMWJIfRqtzOC35Qs9Ghho7EZjZ+FToXqI56ba1TPnSx8ws\n55wIzMxyzonAzCznnAjMzHLOicDMLOecCMzMcs6JwMws55wIzMxyTmXWhRlTJHUCjw1z9znAthEM\nZzxwnfPBdc6HA6nz4RFRdWWvcZEIDoSktRHRUe84RpPrnA+ucz6MRp3dNWRmlnNOBGZmOZeHRLCi\n3gHUgeucD65zPmRe54YfIzAzs8ry0CIwM7MKGjoRSFos6UFJf5B0Rb3jGQpJh0m6W9LvJN0v6bK0\nfJakOyU9lP6dWbTP8rSuD0p6bVH5KZJ+m277opSsMi9pkqRvp+WrJS0Y7XoOJqlZ0n2SVqafG7q+\nAJJmSLpZ0mZJD0h6eSPXW9IH0v+mN0n6lqTJjVhfSd+QtFXSpqKyUamnpEvSYzwk6ZKqwUZEQ76A\nZuBh4EigBdgAHF/vuIYQ/1zg5PT9NOD3wPHAp4Er0vIrgE+l749P6zgJOCKte3O6bQ1wGiDgduA/\np+XvBv4tfX8h8O0xUO8PAv8OrEw/N3R901iuBd6Rvm8BZjRqvYFDgUeAKennm4C3NWJ9gb8FTgY2\nFZVlXk9gFvDH9O/M9P3MirHW+3+CDP8lvBy4o+jzcmB5veM6gPrcCrwGeBCYm5bNBR4sVT/gjvSf\nwVxgc1H5W4CvFn8nfT+BZNKK6ljHecBdwNnsTQQNW980jukkJ0YNKm/IepMkgj+lJ6kJwErgnAau\n7wL2TQSZ17P4O+m2rwJvqRRnI3cNFf6DK3giLRt30ibfScBq4EUR8VS66WngRen7cvU9NH0/uHyf\nfSKiD3gGmD3iFajd1cAyoHjl8kauLyRXf53A/0m7xK6R1EqD1jsingQ+CzwOPAU8ExE/okHrW8Jo\n1HPI575GTgQNQVIb8F3g/RHxbPG2SNJ9Q9z2JWkJsDUi1pX7TiPVt8gEku6Df42Ik4Buki6DPRqp\n3mmf+AUkCfDFQKuki4q/00j1rWQs1bORE8GTwGFFn+elZeOGpIkkSeCGiLglLf6zpLnp9rnA1rS8\nXH2fTN8PLt9nH0kTSLopto98TWpyBnC+pEeBG4GzJV1P49a34AngiYhYnX6+mSQxNGq9Xw08EhGd\nEbEbuAU4ncat72CjUc8hn/saORH8Bjha0hGSWkgGU26rc0w1S+8M+DrwQER8vmjTbUDhLoBLSMYO\nCuUXpncSHAEcDaxJm6HPSjot/c2LB+1T+K03Aj9Jr1JGXUQsj4h5EbGA5N/VTyLiIhq0vgUR8TTw\nJ0nHpkWvAn5H49b7ceA0SVPTOF8FPEDj1new0ajnHcA5kmamLbBz0rLy6jGAMooDNeeS3G3zMPDR\nesczxNj/hqTZuBFYn77OJekDvAt4CPgxMKton4+mdX2Q9M6CtLwD2JRu+xJ7JxJOBr4D/IHkzoQj\n613vNK6z2DtYnIf6LgLWpv+uv09yp0fD1hu4EticxnodyZ0yDVdf4Fsk4yC7SVp+/zha9QTenpb/\nAfiHarF6ZrGZWc41cteQmZnVwInAzCznnAjMzHLOicDMLOecCMzMcs6JwHJBUlf6d4Gk/zrCv/2R\nQZ9/NZK/b5Y1JwLLmwXAkBJBOmuzkn0SQUScPsSYzOrKicDy5irgFZLWp8/Fb5b0GUm/kbRR0jsB\nJJ0l6eeSbiOZ6Yuk70tap+RZ+kvTsquAKenv3ZCWFVofSn97U/o8+TcX/fYq7V2D4IaiZ8xfpWQN\nio2SPjvq/3Qsl6pd6Zg1miuAyyNiCUB6Qn8mIl4qaRLwS0k/Sr97MnBCRDySfn57ROyQNAX4jaTv\nRsQVkv5bRCwqcaw3kMwaPhGYk+7zs3TbScBLgC3AL4EzJD0A/BfguIgISTNGvPZmJbhFYHl3DnCx\npPUkj/meTfKcF0ie9fJI0XffJ2kDcA/JQ72OprK/Ab4VEf0R8Wfgp8BLi377iYgYIHl8yAKSxwi/\nAHxd0huAXQdcO7MaOBFY3gl4b0QsSl9HRPJ8fEgeCZ18STqL5MmZL4+IE4H7SJ71Mlw9Re/7gQmR\nPFP+VJInkC4BfngAv29WMycCy5vnSJb+LLgDuDR95DeSjkkXhhlsOvCXiNgl6TiSpQMLdhf2H+Tn\nwJvTcYh2kqUL15QLLF17YnpE/D/gAyRdSmaZ8xiB5c1GoD/t4vm/wBdIumXuTQdsO4HXl9jvh8C7\n0n78B0m6hwpWABsl3RsRby0q/x7JcoMbSJ4kuywink4TSSnTgFslTSZpqXxweFU0Gxo/fdTMLOfc\nNWRmlnNOBGZmOedEYGaWc04EZmY550RgZpZzTgRmZjnnRGBmlnNOBGZmOff/AWXJQFzjmqbEAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11440a278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iters, winRates)\n",
    "plt.plot(rIters, randRates)\n",
    "plt.ylabel('Win rate (%)')\n",
    "plt.xlabel('Iterations')\n",
    "# plt.figure(figsize=(14,4), dpi=160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Betting Strategy and Earnings **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "*The things we learned.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
